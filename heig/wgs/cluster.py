import os
import time
import shutil
import numpy as np
import pandas as pd
import heig.input.dataset as ds
from heig.wgs.gwas import DoGWAS
from heig.wgs.null import fit_null_model
from heig.wgs.relatedness import LOCOpreds
from heig.wgs.utils import read_genotype_data, init_hail, get_temp_path
from heig.sumstats import GWASHEIG, read_sumstats
from heig.voxelgwas import VGWAS, write_header, voxel_reader, process_voxels


"""
cluster inference

input:
1. ldr + covar + bases
2. geno-mt, bfile or vcf
3. sig threshold
4. number of bootstrap samples
5. voxel-variant associations

output:
1. null distribution of cluster size 
2. screened voxel-variant associations

"""


class Cluster:
    """
    Computing cluster size (i.e., number of associated voxels) 
    for SNPs in a bootstrap sample

    1. LDR GWAS
    2. LDR summary statistics process
    3. voxel-level GWAS reconstruction
    4. count cluster size for each sample-SNP pair
    
    """
    def __init__(
            self, 
            gprocessor, 
            resid_ldrs, 
            covar,
            bases, 
            voxels,
            temp_path, 
            sig_thresh, 
            threads=1, 
            loco_preds=None
        ):
        """
        Parameters:
        ------------
        gprocessor: a GProcessor instance including hail.MatrixTable
        resid_ldrs: a pd.DataFrame of LDR residuals with a single index 'IID'
        covar: a pd.DataFrame of covariates with a single index 'IID'
        bases: a np.array of bases
        voxels: a np.array of voxels numeric indices
        temp_path: a temporary path for saving interim data
        sig_thresh: significant threshold
        threads: number of threads
        loco_preds: a LOCOpreds instance of loco predictions
            loco_preds.data_reader(j) returns loco preds for chrj with matched subjects
        
        """
        self.gprocessor = gprocessor
        self.resid_ldrs = resid_ldrs
        self.covar = covar
        self.bases = bases
        self.voxels = voxels
        self.temp_path = temp_path
        self.sig_thresh = sig_thresh
        self.threads = threads
        self.loco_preds = loco_preds
        self.n_sub = resid_ldrs.shape[0]
        self.cols_map, self.cols_map2 = self._map_cols()

    @staticmethod
    def _map_cols():
        """
        Creating two dicts for mapping provided colnames and standard colnames

        Returns:
        ---------
        cols_map: keys are standard colnames, values are provided colnames
        cols_map2: keys are provided colnames, values are standard colnames

        """
        cols_map = dict()
        cols_map["N"] = 'n_called'
        cols_map["CHR"] = 'chr'
        cols_map["POS"] = 'pos'
        cols_map["SNP"] = 'rsid'
        cols_map["EFFECT"] = 'effect'
        cols_map["null_value"] = 0
        cols_map["SE"] = 'standard_error'
        cols_map["A1"] = 'alt_allele'
        cols_map["A2"] = 'ref_allele'
        cols_map["Z"] = 't_stat'

        cols_map2 = dict()
        for k, v in cols_map.items():
            if v is not None and k not in ("n", "maf_min", "info_min", "null_value"):
                cols_map2[v] = k

        return cols_map, cols_map2

    def _generate_sample(self):
        """
        A bootstrap sample is generated by v_i*\xi_{ij} for j = 1...r
        
        """
        rand_v = np.random.randn(self.n_sub).reshape(-1, 1)
        return rand_v

    def _do_ldr_gwas(self, rand_v):
        """
        A wrapper function for doing LDR GWAS
        TODO: if too many LDRs, need to do LDR GWAS separately

        """
        ldr_gwas = DoGWAS(
            self.gprocessor, 
            self.resid_ldrs, 
            self.covar,
            self.temp_path, 
            self.loco_preds, 
            rand_v
        )
        ldr_gwas.save(f"{self.temp_path}_bootstrap_ldr_gwas")

    def _process_sumstats(self):
        """
        A wrapper function for processing LDR sumstats
        
        """
        sumstats = GWASHEIG(
            f"{self.temp_path}_bootstrap_ldr_gwas.parquet",
            self.cols_map,
            self.cols_map2,
            f"{self.temp_path}_bootstrap_ldr_sumstats"
        )
        sumstats.process(self.threads)

    def _do_vgwas(self, rand_v):
        """
        A wrapper function for voxel-level GWAS reconstruction
        
        """
        rand_resid_ldrs = self.resid_ldrs.values() * rand_v
        ldr_cov = np.dot(rand_resid_ldrs, rand_resid_ldrs) / self.n
        sumstats = read_sumstats(f"{self.temp_path}_bootstrap_ldr_sumstats")
        ldr_n = np.array(sumstats.snpinfo["N"]).reshape(-1, 1)
        snp_idxs = np.ones(self.n, dtype=bool)
        write_header(sumstats.snpinfo, f"{self.temp_path}_bootstrap_vgwas.txt")
        vgwas = VGWAS(self.bases, ldr_cov, sumstats, snp_idxs, ldr_n, self.threads)

        for voxel_idxs in voxel_reader(np.sum(snp_idxs), self.voxels):
            voxel_beta = vgwas.recover_beta(voxel_idxs, self.threads)
            voxel_se = vgwas.recover_se(voxel_idxs, voxel_beta)
            voxel_z = voxel_beta / voxel_se
            all_sig_idxs = np.ones(voxel_z.shape, dtype=bool)
            all_sig_idxs_voxel = all_sig_idxs.any(axis=0)

            process_voxels(
                voxel_idxs,
                all_sig_idxs,
                sumstats.snpinfo,
                voxel_beta,
                voxel_se,
                voxel_z,
                all_sig_idxs_voxel,
                f"{self.temp_path}_bootstrap_vgwas.txt",
                self.threads,
            )

    def cluster_analysis(self):
        """
        The main function for computing cluster size for a bootstrap sample
        
        """
        rand_v = self._generate_sample()
        self._do_ldr_gwas(rand_v)
        self._process_sumstats()
        self._do_vgwas(rand_v)

        vgwas = pd.read_csv(f"{self.temp_path}_bootstrap_vgwas.txt", sep="\t")
        vgwas["sig"] = vgwas["P"] < self.sig_thresh
        null_cluster_size = list(vgwas.groupby("SNP")["sig"].apply(sum))

        return null_cluster_size


def calculate_resid_ldrs(ldrs, covar):
    """
    resid_ldrs: a pd.DataFrame of LDR residuals with a single index 'IID'
    covar: a pd.DataFrame of covariates with a single index 'IID'
    
    """
    ldrs_array = ldrs.values()
    covar_array = covar.values()
    resid_ldrs = fit_null_model(ldrs_array, covar_array)
    resid_ldrs = pd.DataFrame(resid_ldrs)
    resid_ldrs.index = ldrs.index

    return resid_ldrs



def check_input(args, log):
    # required arguments
    if args.ldrs is None:
        raise ValueError("--ldrs is required")
    if args.covar is None:
        raise ValueError("--covar is required")
    if args.spark_conf is None:
        raise ValueError("--spark-conf is required")
    if args.bfile is None and args.geno_mt is None:
        raise ValueError("either --bfile or --geno-mt is required")
    elif args.bfile is not None and args.geno_mt is not None:
        log.info("WARNING: --bfile is ignored if --geno-mt is provided")
        args.bfile = None
    if args.bases is None:
        raise ValueError("--bases is required")
    if args.ldr_cov is None:
        raise ValueError("--ldr-cov is required")
    if args.sig_thresh is None:
        raise ValueError("--sig-thresh is required")
    
    if args.n_bootstrap is None:
        args.n_bootstrap = 1000
    args.voxels
    args.keep
    args.remove
    args.extract
    args.exclude
    args.threads
    args.n_bootstrap
    args.sig_thresh
    args.spark_conf
    args.grch37
    args.n_ldrs
    args.not_save_genotype_data
    pass


def run(args, log):
    check_input(args)
    init_hail(args.spark_conf, args.grch37, args.out, log)
    
    # read LDRs, bases, ldr_cov, and covariates
    ldrs = ds.Dataset(args.ldrs)
    log.info(f"Read LDRs from {args.ldrs}")
    log.info(f"{ldrs.data.shape[1]} LDRs and {ldrs.data.shape[0]} subjects.")
    ldr_cov = np.load(args.ldr_cov)
    log.info(f"Read variance-covariance matrix of LDRs from {args.ldr_cov}")
    bases = np.load(args.bases)
    log.info(f"{bases.shape[1]} bases read from {args.bases}")
    covar = ds.Covar(args.covar, args.cat_covar_list)
    log.info(f"Read covariates from {args.covar}")

    # keep selected LDRs
    if args.n_ldrs is not None:
        bases, ldr_cov, _, ldrs.data= ds.keep_ldrs(args.n_ldrs, bases, ldr_cov, ldrs.data)
        log.info(f"Keep the top {args.n_ldrs} LDRs.")

    try:
        # read loco preds
        if args.loco_preds is not None:
            log.info(f"Read LOCO predictions from {args.loco_preds}")
            loco_preds = LOCOpreds(args.loco_preds)
            loco_preds.select_ldrs(list(range(args.n_ldrs)))
            if loco_preds.n_ldrs != ldrs.data.shape[1]:
                raise ValueError(
                    (
                        "inconsistent dimension in LDRs and LDR LOCO predictions. "
                        "Try to use --n-ldrs"
                    )
                )
            common_ids = ds.get_common_idxs(
                ldrs.data.index,
                covar.data.index,
                loco_preds.ids,
                args.keep,
            )
        else:
            # keep subjects
            common_ids = ds.get_common_idxs(
                ldrs.data.index, covar.data.index, args.keep
            )
        common_ids = ds.remove_idxs(common_ids, args.remove, single_id=True)

        # read genotype data
        gprocessor = read_genotype_data(args, log)

        log.info(f"Processing genetic data ...")
        gprocessor.extract_exclude_snps(args.extract, args.exclude)
        gprocessor.extract_chr_interval(args.chr_interval)
        gprocessor.keep_remove_idvs(common_ids)
        gprocessor.do_processing(mode="gwas")
        gprocessor.check_valid()

        temp_path = get_temp_path()
        if not args.not_save_genotype_data:
            gprocessor.save_interim_data(temp_path)

        # extract common subjects and align data
        snps_mt_ids = gprocessor.subject_id()
        ldrs.to_single_index()
        covar.to_single_index()
        ldrs.keep_and_remove(snps_mt_ids)
        covar.keep_and_remove(snps_mt_ids)
        covar.cat_covar_intercept()

        if args.loco_preds is not None:
            loco_preds.keep(snps_mt_ids)
        else:
            loco_preds = None
        log.info(f"{len(snps_mt_ids)} common subjects in the data.")
        log.info(
            f"{covar.data.shape[1]} fixed effects in the covariates (including the intercept)."
        )

        # fit null model
        resid_ldrs = calculate_resid_ldrs(ldrs.data, covar.data)

        # wild bootstrap
        null_cluster_size_list = list()
        cluster = Cluster(gprocessor, resid_ldrs, covar.data, temp_path, loco_preds)
        for _ in range(args.n_bootstrap):
            null_cluster_size = cluster.cluster_analysis()
            null_cluster_size_list.append(null_cluster_size)
        null_cluster_size_pd = pd.DataFrame(null_cluster_size_list)

        # save results
        null_cluster_size_pd.to_csv(args.out, header=None, sep="\t", index=None)
        log.info(f"\nSave null distribution of cluster size to {args.out}")

    finally:
        if "temp_path" in locals():
            if os.path.exists(temp_path):
                for _ in range(3):
                    try:
                        shutil.rmtree(temp_path)
                        break
                    except OSError as e:
                        if e.errno == 39:  # Directory not empty
                            time.sleep(0.1)
                        else:
                            raise
            if os.path.exists(f"{temp_path}_covar.txt"):
                os.remove(f"{temp_path}_covar.txt")
            if os.path.exists(f"{temp_path}_ldr.txt"):
                os.remove(f"{temp_path}_ldr.txt")
            if os.path.exists(f"{temp_path}_bootstrap_ldr_gwas.parquet"):
                shutil.rmtree(f"{temp_path}_bootstrap_ldr_gwas.parquet")
            if os.path.exists(f"{temp_path}_bootstrap_ldr_sumstats"):
                os.remove(f"{temp_path}_bootstrap_ldr_sumstats.sumstats")
                os.remove(f"{temp_path}_bootstrap_ldr_sumstats.snpinfo")
            if os.path.exists(f"{temp_path}_bootstrap_vgwas.txt"):
                os.remove(f"{temp_path}_bootstrap_vgwas.txt")
        if args.loco_preds is not None:
            loco_preds.close()

    

    